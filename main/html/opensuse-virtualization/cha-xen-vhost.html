<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Setting up a virtual machine host | Virtualization Guide | openSUSE Leap 15.6</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" />
<meta name="title" content="Setting up a virtual machine host | openSUSE Leap 15.6" />
<meta name="description" content="This section documents how to set up and use openSUSE Leap 15.6 as a virtual machine host." />
<meta name="product-name" content="openSUSE Leap" />
<meta name="product-number" content="15.6" />
<meta name="book-title" content="Virtualization Guide" />
<meta name="chapter-title" content="Chapter 23. Setting up a virtual machine host" />
<meta name="tracker-url" content="https://bugzilla.opensuse.org/enter_bug.cgi" />
<meta name="tracker-type" content="bsc" />
<meta name="tracker-bsc-assignee" content="fs@suse.com" />
<meta name="tracker-bsc-component" content="Documentation" />
<meta name="tracker-bsc-product" content="openSUSE Distribution" />
<meta name="tracker-bsc-version" content="Leap 15.4" />
<meta property="og:title" content="Setting up a virtual machine host | openSUSE Leap 15.6" />
<meta property="og:description" content="This section documents how to set up and use openSUSE Leap 15.6 as a virtual machine host." />
<meta property="og:type" content="article" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Setting up a virtual machine host | openSUSE Leap 15.6" />
<meta name="twitter:description" content="This section documents how to set up and use openSUSE Leap 15.6 as a virtual machine host." />
<link rel="home" href="index.html" title="openSUSE Leap Documentation" /><link rel="up" href="part-virt-xen.html" title="Part IV. Managing virtual machines with Xen" /><link rel="prev" href="part-virt-xen.html" title="Part IV. Managing virtual machines with Xen" /><link rel="next" href="cha-xen-network.html" title="Chapter 24. Virtual networking" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css" /></noscript><script src="static/js/jquery-1.12.4.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-navigation">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #E11;"><div id="_header"><div id="_logo"><img src="static/images/logo.svg" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="Virtualization Guide"><span class="book-icon">Virtualization Guide</span></a><span> › </span><a class="crumb" href="part-virt-xen.html">Managing virtual machines with Xen</a><span> › </span><a class="crumb" href="cha-xen-vhost.html">Setting up a virtual machine host</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>Virtualization Guide</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="cha-kvm.html"><span class="number"> </span><span class="name">Preface</span></a></li><li class="inactive"><a href="part-virt-intro.html"><span class="number">I </span><span class="name">Introduction</span></a><ol><li class="inactive"><a href="chap-virtualization-introduction.html"><span class="number">1 </span><span class="name">Virtualization technology</span></a></li><li class="inactive"><a href="cha-virtualization-scenarios.html"><span class="number">2 </span><span class="name">Virtualization scenarios</span></a></li><li class="inactive"><a href="cha-xen-basics.html"><span class="number">3 </span><span class="name">Introduction to Xen virtualization</span></a></li><li class="inactive"><a href="cha-kvm-intro.html"><span class="number">4 </span><span class="name">Introduction to KVM virtualization</span></a></li><li class="inactive"><a href="cha-tools-intro.html"><span class="number">5 </span><span class="name">Virtualization tools</span></a></li><li class="inactive"><a href="cha-vt-installation.html"><span class="number">6 </span><span class="name">Installation of virtualization components</span></a></li></ol></li><li class="inactive"><a href="part-virt-libvirt.html"><span class="number">II </span><span class="name">Managing virtual machines with <code class="systemitem">libvirt</code></span></a><ol><li class="inactive"><a href="cha-libvirt-overview.html"><span class="number">7 </span><span class="name"><code class="systemitem">libvirt</code> daemons</span></a></li><li class="inactive"><a href="cha-libvirt-host.html"><span class="number">8 </span><span class="name">Preparing the VM Host Server</span></a></li><li class="inactive"><a href="cha-kvm-inst.html"><span class="number">9 </span><span class="name">Guest installation</span></a></li><li class="inactive"><a href="cha-libvirt-managing.html"><span class="number">10 </span><span class="name">Basic VM Guest management</span></a></li><li class="inactive"><a href="cha-libvirt-connect.html"><span class="number">11 </span><span class="name">Connecting and authorizing</span></a></li><li class="inactive"><a href="cha-libvirt-storage.html"><span class="number">12 </span><span class="name">Advanced storage topics</span></a></li><li class="inactive"><a href="cha-libvirt-config-gui.html"><span class="number">13 </span><span class="name">Configuring virtual machines with Virtual Machine Manager</span></a></li><li class="inactive"><a href="cha-libvirt-config-virsh.html"><span class="number">14 </span><span class="name">Configuring virtual machines with <code class="command">virsh</code></span></a></li><li class="inactive"><a href="sec-libvirt-admin-migrate.html"><span class="number">15 </span><span class="name">Migrating VM Guests</span></a></li><li class="inactive"><a href="xen2kvm-migration.html"><span class="number">16 </span><span class="name">Xen to KVM migration guide</span></a></li></ol></li><li class="inactive"><a href="part-virt-common.html"><span class="number">III </span><span class="name">Hypervisor-independent features</span></a><ol><li class="inactive"><a href="cha-cachemodes.html"><span class="number">17 </span><span class="name">Disk cache modes</span></a></li><li class="inactive"><a href="sec-kvm-managing-clock.html"><span class="number">18 </span><span class="name">VM Guest clock settings</span></a></li><li class="inactive"><a href="chap-guestfs.html"><span class="number">19 </span><span class="name">libguestfs</span></a></li><li class="inactive"><a href="cha-qemu-ga.html"><span class="number">20 </span><span class="name">QEMU guest agent</span></a></li><li class="inactive"><a href="tpm.html"><span class="number">21 </span><span class="name">Software TPM emulator</span></a></li><li class="inactive"><a href="virt-crash-dump.html"><span class="number">22 </span><span class="name">Creating crash dumps of a VM Guest</span></a></li></ol></li><li class="inactive"><a href="part-virt-xen.html"><span class="number">IV </span><span class="name">Managing virtual machines with Xen</span></a><ol><li class="inactive"><a href="cha-xen-vhost.html"><span class="number">23 </span><span class="name">Setting up a virtual machine host</span></a></li><li class="inactive"><a href="cha-xen-network.html"><span class="number">24 </span><span class="name">Virtual networking</span></a></li><li class="inactive"><a href="cha-xen-manage.html"><span class="number">25 </span><span class="name">Managing a virtualization environment</span></a></li><li class="inactive"><a href="cha-xen-vbd.html"><span class="number">26 </span><span class="name">Block devices in Xen</span></a></li><li class="inactive"><a href="cha-xen-config.html"><span class="number">27 </span><span class="name">Virtualization: configuration options and settings</span></a></li><li class="inactive"><a href="cha-xen-admin.html"><span class="number">28 </span><span class="name">Administrative tasks</span></a></li><li class="inactive"><a href="cha-xen-xenstore.html"><span class="number">29 </span><span class="name">XenStore: configuration database shared between domains</span></a></li><li class="inactive"><a href="cha-xen-ha.html"><span class="number">30 </span><span class="name">Xen as a high-availability virtualization host</span></a></li><li class="inactive"><a href="pv-to-fv.html"><span class="number">31 </span><span class="name">Xen: converting a paravirtual (PV) guest into a fully virtual (FV/HVM) guest</span></a></li></ol></li><li class="inactive"><a href="part-virt-qemu.html"><span class="number">V </span><span class="name">Managing virtual machines with QEMU</span></a><ol><li class="inactive"><a href="cha-qemu-overview.html"><span class="number">32 </span><span class="name">QEMU overview</span></a></li><li class="inactive"><a href="cha-qemu-host.html"><span class="number">33 </span><span class="name">Setting up a KVM VM Host Server</span></a></li><li class="inactive"><a href="cha-qemu-guest-inst.html"><span class="number">34 </span><span class="name">Guest installation</span></a></li><li class="inactive"><a href="cha-qemu-running.html"><span class="number">35 </span><span class="name">Running virtual machines with qemu-system-ARCH</span></a></li><li class="inactive"><a href="cha-qemu-monitor.html"><span class="number">36 </span><span class="name">Virtual machine administration using QEMU monitor</span></a></li></ol></li><li class="inactive"><a href="part-virt-troubleshoot.html"><span class="number">VI </span><span class="name">Troubleshooting</span></a><ol><li class="inactive"><a href="cha-virt-help.html"><span class="number">37 </span><span class="name">Integrated help and package documentation</span></a></li><li class="inactive"><a href="cha-virt-logs.html"><span class="number">38 </span><span class="name">Gathering system information and logs</span></a></li></ol></li><li class="inactive"><a href="gloss-vt-glossary.html"><span class="number"> </span><span class="name">Glossary</span></a></li><li class="inactive"><a href="app-gpu-passthru.html"><span class="number">A </span><span class="name">Configuring GPU Pass-Through for NVIDIA cards</span></a></li><li class="inactive"><a href="bk06apb.html"><span class="number">B </span><span class="name">GNU licenses</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Part IV. Managing virtual machines with Xen" href="part-virt-xen.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 24. Virtual networking" href="cha-xen-network.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" style="background-color: #E11;" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="Virtualization Guide"><span class="book-icon">Virtualization Guide</span></a><span> › </span><a class="crumb" href="part-virt-xen.html">Managing virtual machines with Xen</a><span> › </span><a class="crumb" href="cha-xen-vhost.html">Setting up a virtual machine host</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Part IV. Managing virtual machines with Xen" href="part-virt-xen.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 24. Virtual networking" href="cha-xen-network.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="cha-xen-vhost"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname "><span class="productname"><span class="phrase">openSUSE Leap</span></span></span> <span class="productnumber "><span class="productnumber"><span class="phrase">15.6</span></span></span></div><div><h2 class="title"><span class="number">23 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting up a virtual machine host</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>cha-xen-vhost</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-best"><span class="number">23.1 </span><span class="name">Best practices and suggestions</span></a></span></dt><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-memory"><span class="number">23.2 </span><span class="name">Managing Dom0 memory</span></a></span></dt><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-netcard"><span class="number">23.3 </span><span class="name">Network card in fully virtualized guests</span></a></span></dt><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-start"><span class="number">23.4 </span><span class="name">Starting the virtual machine host</span></a></span></dt><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-pciback"><span class="number">23.5 </span><span class="name">PCI Pass-Through</span></a></span></dt><dt><span class="sect1"><a href="cha-xen-vhost.html#sec-xen-vhost-usbpass"><span class="number">23.6 </span><span class="name">USB pass-through</span></a></span></dt></dl></div></div><p>
    This section documents how to set up and use <span class="productname"><span class="phrase">openSUSE Leap</span></span> <span class="productnumber"><span class="phrase">15.6</span></span>
    as a virtual machine host.
  </p><p>
    The hardware requirements for the Dom0 are often the same as those for
    the <span class="productname"><span class="phrase">openSUSE Leap</span></span> operating system. Additional CPU, disk, memory and
    network resources should be added to accommodate the resource demands of
    all planned VM Guest systems.
  </p><div id="id-1.8.6.2.5" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg" /><h6>Tip: Resources</h6><p>
      Remember that VM Guest systems, like physical machines, perform better
      when they run on faster processors and have access to more system memory.
    </p></div><p>
    The virtual machine host requires several software packages and their
    dependencies to be installed. To install all necessary packages, run YaST
    <span class="guimenu ">Software Management</span>, select
    <span class="guimenu ">View</span> › <span class="guimenu ">Patterns</span> and choose <span class="guimenu ">Xen Virtual
    Machine Host Server</span> for installation. The installation can also
    be performed with YaST using the module
    <span class="guimenu ">Virtualization</span> › <span class="guimenu ">Install Hypervisor
    and Tools</span>.
  </p><p>
    After the Xen software is installed, restart the computer and, on the
    boot screen, choose the newly added option with the Xen kernel.
  </p><p>
    Updates are available through your update channel. To be sure to have the
    latest updates installed, run YaST <span class="guimenu ">Online Update</span> after
    the installation has finished.
  </p><div class="sect1 " id="sec-xen-vhost-best"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Best practices and suggestions</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-best">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-best</li></ul></div></div></div></div><p>
      When installing and configuring the <span class="productname"><span class="phrase">openSUSE Leap</span></span> operating system on the
      host, be aware of the following best practices and suggestions:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
          If the host should always run as Xen host, run YaST <span class="guimenu ">System</span> › <span class="guimenu ">Boot Loader</span> and activate the Xen boot entry as default boot
          section.
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              In YaST, click <span class="guimenu ">System &gt; Boot Loader</span>.
            </p></li><li class="listitem "><p>
              Change the default boot to the <span class="guimenu ">Xen</span> label,
              then click <span class="guimenu ">Set as Default</span>.
            </p></li><li class="listitem "><p>
              Click <span class="guimenu ">Finish</span>.
            </p></li></ul></div></li><li class="listitem "><p>
          For best performance, only the applications and processes required
          for virtualization should be installed on the virtual machine host.
        </p></li><li class="listitem "><p>
          If you intend to use a watchdog device attached to the Xen host,
          use only one at a time. It is recommended to use a driver with actual
          hardware integration over a generic software one.
        </p></li></ul></div><div id="id-1.8.6.2.9.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note: Hardware monitoring</h6><p>
        The Dom0 kernel is running virtualized, so tools like
        <code class="command">irqbalance</code> or <code class="command">lscpu</code> do not
        reflect the real hardware characteristics.
      </p></div><div id="id-1.8.6.2.9.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg" /><h6>Important: Trusted boot not supported by Xen</h6><p>
        Trusted boot (Tboot) is not supported by Xen. To ensure that the Xen
        host boots correctly, verify that the <span class="guimenu ">Enable Trusted Boot
        Support</span> option is deactivated in the GRUB 2 configuration
        dialog.
      </p></div></div><div class="sect1 " id="sec-xen-vhost-memory"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing Dom0 memory</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-memory">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-memory</li></ul></div></div></div></div><p>
      In previous versions of <span class="productname"><span class="phrase">openSUSE Leap</span></span>, the default memory allocation
      scheme of a Xen host was to allocate all host physical memory to Dom0
      and enable auto-ballooning. Memory was automatically ballooned from
      Dom0 when additional domains were started. This behavior has always
      been error prone and disabling it was strongly encouraged. Starting with
      <span class="productname"><span class="phrase">openSUSE Leap</span></span> <span class="phrase">15.1</span>, auto-ballooning has been
      disabled by default and Dom0 is given 10% of host physical memory +
      1 GB. For example, on a host with 32 GB of physical memory,
      4.2 GB of memory is allocated for Dom0.
    </p><p>
      The use of the <code class="option">dom0_mem</code> Xen command line option in
      <code class="filename">/etc/default/grub</code> is still supported and encouraged.
      You can restore the old behavior by setting <code class="option">dom0_mem</code> to
      the host physical memory size and enabling the
      <code class="option">autoballoon</code> setting in
      <code class="filename">/etc/xen/xl.conf</code>.
    </p><div id="id-1.8.6.2.10.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning: Insufficient memory for Dom0</h6><p>
        The amount of memory reserved for Dom0 is a function of the number of
        VM Guests running on the host since Dom0 provides back-end network
        and disk I/O services for each VM Guest. Other workloads running in
        Dom0 should also be considered when calculating Dom0 memory
        allocation. Memory sizing of Dom0 should be determined like any other
        virtual machine.
      </p></div><div class="sect2 " id="sec-xen-vhost-maxmem"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting Dom0 memory allocation</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-maxmem">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-maxmem</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
            Determine memory allocation required for Dom0.
          </p></li><li class="step "><p>
            At Dom0, type <code class="command">xl info</code> to view the amount of
            memory that is available on the machine. Dom0's current memory
            allocation can be determined with the <code class="command">xl list</code>
            command.
          </p></li><li class="step "><p>
            Edit <code class="filename">/etc/default/grub</code> and adjust the
            <code class="option">GRUB_CMDLINE_XEN</code> option so that it includes
            <code class="literal">dom0_mem=<em class="replaceable ">MEM_AMOUNT</em></code>.
            Replace <em class="replaceable ">MEM_AMOUNT</em> with the maximum
            amount of memory to allocate to Dom0. Add <code class="command">K</code>,
            <code class="command">M</code>, or <code class="command">G</code>, to specify the size
            unit. For example:
          </p><div class="verbatim-wrap"><pre class="screen">GRUB_CMDLINE_XEN="dom0_mem=2G"</pre></div></li><li class="step "><p>
            Restart the computer to apply the changes.
          </p></li></ol></div></div><div id="id-1.8.6.2.10.5.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg" /><h6>Tip</h6><p>
          Refer to <span class="intraxref">Book “Reference”, Chapter 12 “The boot loader GRUB 2”, Section 12.2.2 “The file <code class="filename">/etc/default/grub</code>”</span> for more
          details about Xen-related boot configuration options.
        </p></div><div id="id-1.8.6.2.10.5.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning: Xen Dom0 memory</h6><p>
          When using the XL tool stack and the <code class="command">dom0_mem=</code>
          option for the Xen hypervisor in GRUB 2 you need to disable xl
          <span class="emphasis"><em>autoballoon</em></span> in
          <code class="filename">etc/xen/xl.conf</code>. Otherwise launching VMs fails
          with errors about not being able to balloon down Dom0. So add
          <span class="emphasis"><em>autoballoon=0</em></span> to <code class="filename">xl.conf</code> if
          you have the <code class="command">dom0_mem=</code> option specified for Xen.
          Also see
          <a class="link" href="https://wiki.xen.org/wiki/Xen_Best_Practices#Xen_dom0_dedicated_memory_and_preventing_dom0_memory_ballooning" target="_blank">Xen
          dom0 memory</a>
        </p></div></div></div><div class="sect1 " id="sec-xen-vhost-netcard"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Network card in fully virtualized guests</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-netcard">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-netcard</li></ul></div></div></div></div><p>
      In a fully virtualized guest, the default network card is an emulated
      Realtek network card. However, it also possible to use the split network
      driver to run the communication between Dom0 and a VM Guest. By
      default, both interfaces are presented to the VM Guest, because the
      drivers of certain operating systems require both to be present.
    </p><p>
      When using <span class="productname"><span class="phrase">openSUSE Leap</span></span>, only the paravirtualized network cards are
      available for the VM Guest by default. The following network options are
      available:
    </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.8.6.2.11.4.1"><span class="term ">emulated</span></dt><dd><p>
            To use an emulated network interface like an emulated Realtek card,
            specify <code class="literal">type=ioemu</code> in the <code class="literal">vif</code>
            device section of the domain xl configuration. An example
            configuration would look like:
          </p><div class="verbatim-wrap"><pre class="screen">vif = [ 'type=ioemu,mac=00:16:3e:5f:48:e4,bridge=br0' ]</pre></div><p>
            Find more details about the xl configuration in the
            <code class="filename">xl.conf</code> man page <code class="command">man 5
            xl.conf</code>.
          </p></dd><dt id="id-1.8.6.2.11.4.2"><span class="term ">paravirtualized</span></dt><dd><p>
            When you specify <code class="literal">type=vif</code> and do not specify a
            model or type, the paravirtualized network interface is used:
          </p><div class="verbatim-wrap"><pre class="screen">vif = [ 'type=vif,mac=00:16:3e:5f:48:e4,bridge=br0,backen=0' ]</pre></div></dd><dt id="id-1.8.6.2.11.4.3"><span class="term ">emulated and paravirtualized</span></dt><dd><p>
            If the administrator should be offered both options, simply specify
            both type and model. The xl configuration would look like:
          </p><div class="verbatim-wrap"><pre class="screen">vif = [ 'type=ioemu,mac=00:16:3e:5f:48:e4,model=rtl8139,bridge=br0' ]</pre></div><p>
            In this case, one of the network interfaces should be disabled on
            the VM Guest.
          </p></dd></dl></div></div><div class="sect1 " id="sec-xen-vhost-start"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Starting the virtual machine host</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-start">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-start</li></ul></div></div></div></div><p>
      If virtualization software is correctly installed, the computer boots to
      display the GRUB 2 boot loader with a <span class="guimenu ">Xen</span> option on
      the menu. Select this option to start the virtual machine host.
    </p><div id="id-1.8.6.2.12.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning</h6><p>
        When booting a Xen system, you may observe error messages in the
        /var/log/messages log file or <code class="systemitem">systemd</code> journal of dom0 similar to
        following:
      </p><div class="verbatim-wrap"><pre class="screen">isst_if_mbox_pci: probe of 0000:ff:1e.1 failed with error -5
isst_if_pci: probe of 0000:fe:00.1 failed with error -5</pre></div><p>
        Ignore them as they are harmless and are caused by the fact that the
        ISST driver does not provide any power or frequency scaling feature for
        virtual machines.
      </p></div><div id="id-1.8.6.2.12.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note: Xen and Kdump</h6><p>
        In Xen, the hypervisor manages the memory resource. If you need to
        reserve system memory for a recovery kernel in Dom0, this memory needs
        to be reserved by the hypervisor. Thus, it is necessary to add
         <code class="option">crashkernel=size</code> to the
        <code class="varname">GRUB_CMDLINE_XEN_DEFAULT</code> variable in the
        <code class="filename">/etc/dfault/grub</code> file, save it and run the
        following command:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code><code class="command">sudo</code> grub2-mkconfig -o /boot/grub2/grub.cfg</pre></div><p>
        For more information on the crashkernel parameter, see
        <span class="intraxref">Book “System Analysis and Tuning Guide”, Chapter 18 “Kexec and Kdump”, Section 18.4 “Calculating <code class="option">crashkernel</code> allocation size”</span>.
      </p></div><p>
      If the <span class="guimenu ">Xen</span> option is not on the GRUB 2 menu, review
      the steps for installation and verify that the GRUB 2 boot loader has
      been updated. If the installation has been done without selecting the
      Xen pattern, run the YaST <span class="guimenu ">Software Management</span>,
      select the filter <span class="guimenu ">Patterns</span> and choose <span class="guimenu ">Xen
      Virtual Machine Host Server</span> for installation.
    </p><p>
      After booting the hypervisor, the Dom0 virtual machine starts and
      displays its graphical desktop environment. If you did not install a
      graphical desktop, the command line environment appears.
    </p><div id="id-1.8.6.2.12.7" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg" /><h6>Tip: Graphics problems</h6><p>
        Sometimes it may happen that the graphics system does not work
        properly. In this case, add <code class="literal">vga=ask</code> to the boot
        parameters. To activate permanent settings, use
        <code class="literal">vga=mode-0x???</code> where <code class="literal">???</code> is
        calculated as <code class="literal">0x100</code> + VESA mode from
        <a class="link" href="https://en.wikipedia.org/wiki/VESA_BIOS_Extensions" target="_blank">https://en.wikipedia.org/wiki/VESA_BIOS_Extensions</a>,
        for example, <code class="literal">vga=mode-0x361</code>.
      </p></div><p>
      Before starting to install virtual guests, make sure that the system time
      is correct. To do this, configure NTP (Network Time Protocol) on the
      controlling domain:
    </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
          In YaST select <span class="guimenu ">Network Services</span> › <span class="guimenu ">NTP Configuration</span>.
        </p></li><li class="step "><p>
          Select the option to automatically start the NTP daemon during boot.
          Provide the IP address of an existing NTP time server, then click
          <span class="guimenu ">Finish</span>.
        </p></li></ol></div></div><div id="id-1.8.6.2.12.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note: Time services on virtual guests</h6><p>
        Hardware clocks are not precise. All modern operating systems try to
        correct the system time compared to the hardware time bvia an
        additional time source. To get the correct time on all VM Guest
        systems, also activate the network time services on each respective
        guest or make sure that the guest uses the system time of the host. For
        more about <code class="literal">Independent Wallclocks</code> in <span class="productname"><span class="phrase">openSUSE Leap</span></span>
        see <a class="xref" href="sec-kvm-managing-clock.html#sec-xen-guests-suse-time" title="18.2. Xen virtual machine clock settings">Section 18.2, “Xen virtual machine clock settings”</a>.
      </p></div><p>
      For more information about managing virtual machines, see
      <a class="xref" href="cha-xen-manage.html" title="Chapter 25. Managing a virtualization environment">Chapter 25, <em>Managing a virtualization environment</em></a>.
    </p></div><div class="sect1 " id="sec-xen-vhost-pciback"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">PCI Pass-Through</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-pciback">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-pciback</li></ul></div></div></div></div><p>
      To take full advantage of VM Guest systems, it is sometimes necessary to
      assign specific PCI devices to a dedicated domain. When using fully
      virtualized guests, this functionality is only available if the chipset
      of the system supports this feature, and if it is activated from the
      BIOS.
    </p><p>
      This feature is available from both AMD* and Intel*. For AMD machines,
      the feature is called <a class="xref" href="gloss-vt-glossary.html#gloss-vt-acronym-iommu" title="IOMMU">IOMMU</a>. In Intel
      speak, this is <a class="xref" href="gloss-vt-glossary.html#gloss-vt-acronym-vtd" title="VT-d">VT-d</a>. Be aware that
      Intel-VT technology is not sufficient to use this feature for fully
      virtualized guests. To make sure that your computer supports this
      feature, ask your supplier specifically to deliver a system that supports
      PCI Pass-Through.
    </p><div class="itemizedlist "><div class="itemizedlist-title-wrap"><h6 class="itemizedlist-title"><span class="name">Limitations </span><a title="Permalink" class="permalink" href="cha-xen-vhost.html#id-1.8.6.2.13.4">#</a></h6></div><ul class="itemizedlist"><li class="listitem "><p>
          Certain graphics drivers use highly optimized ways to access DMA. This
          is not supported, and thus using graphics cards may be difficult.
        </p></li><li class="listitem "><p>
          When accessing PCI devices behind a
          <a class="xref" href="gloss-vt-glossary.html#gloss-vt-acronym-pcie" title="PCIe">PCIe</a> bridge, all the PCI devices
          must be assigned to a single guest. This limitation does not apply to
          <a class="xref" href="gloss-vt-glossary.html#gloss-vt-acronym-pcie" title="PCIe">PCIe</a> devices.
        </p></li><li class="listitem "><p>
          Guests with dedicated PCI devices cannot be migrated live to a
          different host.
        </p></li></ul></div><p>
      The configuration of PCI Pass-Through is twofold. First, the hypervisor must be
      informed at boot time that a PCI device should be available for
      reassigning. Second, the PCI device must be assigned to the VM Guest.
    </p><div class="sect2 " id="config-hypervisor-pciback"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring the hypervisor for PCI Pass-Through</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#config-hypervisor-pciback">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>config-hypervisor-pciback</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
            Select a device to reassign to a VM Guest. To do this, run
            <code class="command">lspci -k</code>, and read the device number and the
            name of the original module that is assigned to the device:
          </p><div class="verbatim-wrap"><pre class="screen">06:01.0 Ethernet controller: Intel Corporation Ethernet Connection I217-LM (rev 05)
        Subsystem: Dell Device 0617
        Kernel driver in use: e1000e
        Kernel modules: e1000e</pre></div><p>
            In this case, the PCI number is <code class="literal">(06:01.0)</code> and
            the dependent kernel module is <code class="literal">e1000e</code>.
          </p></li><li class="step "><p>
            Specify a module dependency to ensure that
            <code class="systemitem">xen_pciback</code> is the first module to control
            the device. Add the file named
            <code class="filename">/etc/modprobe.d/50-e1000e.conf</code> with the
            following content:
          </p><div class="verbatim-wrap"><pre class="screen">install e1000e /sbin/modprobe xen_pciback ; /sbin/modprobe \
 --first-time --ignore-install e1000e</pre></div></li><li class="step "><p>
            Instruct the <code class="systemitem">xen_pciback</code> module to control
            the device using the <code class="literal">hide</code> option. Edit or create
            <code class="filename">/etc/modprobe.d/50-xen-pciback.conf</code> with the
            following content:
          </p><div class="verbatim-wrap"><pre class="screen">options xen_pciback hide=(06:01.0)</pre></div></li><li class="step "><p>
            Reboot the system.
          </p></li><li class="step "><p>
            Check if the device is in the list of assignable devices with the
            command
          </p><div class="verbatim-wrap"><pre class="screen">xl pci-assignable-list</pre></div></li></ol></div></div><div class="sect3 " id="config-hypervisor-pciback-xl"><div class="titlepage"><div><div><h4 class="title"><span class="number">23.5.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dynamic assignment with xl</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#config-hypervisor-pciback-xl">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>config-hypervisor-pciback-xl</li></ul></div></div></div></div><p>
          To avoid restarting the host system, you can use dynamic assignment
          with xl to use PCI Pass-Through.
        </p><p>
          Begin by making sure that dom0 has the pciback module loaded:
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code><code class="command">sudo</code> modprobe pciback</pre></div><p>
          Then make a device assignable by using <code class="command">xl
          pci-assignable-add</code>. For example, to make the device
          <span class="emphasis"><em>06:01.0</em></span> available for guests, run the command:
        </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">&gt; </code><code class="command">sudo</code> xl pci-assignable-add 06:01.0</pre></div></div></div><div class="sect2 " id="config-hypervisor-pciback-guests"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Assigning PCI devices to VM Guest systems</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#config-hypervisor-pciback-guests">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>config-hypervisor-pciback-guests</li></ul></div></div></div></div><p>
        There are several possibilities to dedicate a PCI device to a
        VM Guest:
      </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.8.6.2.13.7.3.1"><span class="term ">Adding the device while installing:</span></dt><dd><p>
              During installation, add the <code class="literal">pci</code> line to the
              configuration file:
            </p><div class="verbatim-wrap"><pre class="screen">pci=['06:01.0']</pre></div></dd><dt id="id-1.8.6.2.13.7.3.2"><span class="term ">Hotplugging PCI devices to VM Guest systems</span></dt><dd><p>
              The command <code class="literal">xl</code> can be used to add or remove
              PCI devices on the fly. To add the device with number
              <code class="literal">06:01.0</code> to a guest with name
              <code class="literal">sles12</code> use:
            </p><div class="verbatim-wrap"><pre class="screen">xl pci-attach sles12 06:01.0</pre></div></dd><dt id="id-1.8.6.2.13.7.3.3"><span class="term ">Adding the PCI device to Xend</span></dt><dd><p>
              To add the device to the guest permanently, add the following
              snippet to the guest configuration file:
            </p><div class="verbatim-wrap"><pre class="screen">pci = [ '06:01.0,power_mgmt=1,permissive=1' ]</pre></div></dd></dl></div><p>
        After assigning the PCI device to the VM Guest, the guest system must
        care for the configuration and device drivers for this device.
      </p></div><div class="sect2 " id="config-hypervisor-vgaback"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VGA Pass-Through</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#config-hypervisor-vgaback">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>config-hypervisor-vgaback</li></ul></div></div></div></div><p>
        Xen 4.0 and newer supports VGA graphics adapter pass-through on fully
        virtualized VM Guests. The guest can take full control of the graphics
        adapter with high-performance full 3D and video acceleration.
      </p><div class="itemizedlist "><div class="itemizedlist-title-wrap"><h6 class="itemizedlist-title"><span class="name">Limitations </span><a title="Permalink" class="permalink" href="cha-xen-vhost.html#id-1.8.6.2.13.8.3">#</a></h6></div><ul class="itemizedlist"><li class="listitem "><p>
            VGA Pass-Through functionality is similar to PCI Pass-Through and as such also
            requires <a class="xref" href="gloss-vt-glossary.html#gloss-vt-acronym-iommu" title="IOMMU">IOMMU</a> (or Intel VT-d)
            support from the mainboard chipset and BIOS.
          </p></li><li class="listitem "><p>
            Only the primary graphics adapter (the one that is used when you
            power on the computer) can be used with VGA Pass-Through.
          </p></li><li class="listitem "><p>
            VGA Pass-Through is supported only for fully virtualized guests.
            Paravirtual guests (PV) are not supported.
          </p></li><li class="listitem "><p>
            The graphics card cannot be shared between multiple VM Guests
            using VGA Pass-Through—you can dedicate it to one guest only.
          </p></li></ul></div><p>
        To enable VGA Pass-Through, add the following settings to your fully
        virtualized guest configuration file:
      </p><div class="verbatim-wrap"><pre class="screen">gfx_passthru=1
pci=['yy:zz.n']</pre></div><p>
        where <code class="literal">yy:zz.n</code> is the PCI controller ID of the VGA
        graphics adapter as found with <code class="command">lspci -v</code> on Dom0.
      </p></div><div class="sect2 " id="sec-xen-vm-known"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vm-known">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vm-known</li></ul></div></div></div></div><p>
        In certain circumstances, problems may occur during the installation of
        the VM Guest. This section describes several known problems and their
        solutions.
      </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.8.6.2.13.9.3.1"><span class="term ">During boot, the system hangs</span></dt><dd><p>
              The software I/O translation buffer allocates a large chunk of
              low memory early in the bootstrap process. If the requests for
              memory exceed the size of the buffer, it may result in a hung
              boot process. To check if this is the case, switch to console 10
              and check the output there for a message similar to
            </p><div class="verbatim-wrap"><pre class="screen">kernel: PCI-DMA: Out of SW-IOMMU space for 32768 bytes at device 000:01:02.0</pre></div><p>
              In this case, you need to increase the size of the
              <code class="literal">swiotlb</code>. Add
              <code class="literal">swiotlb=<em class="replaceable ">VALUE</em></code>
              (where <em class="replaceable ">VALUE</em> is specified as the
              number of slab entries) on the command line of Dom0. The number
              can be adjusted up or down to find the optimal size for the
              machine.
            </p></dd></dl></div><div id="id-1.8.6.2.13.9.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note: swiotlb a PV guest</h6><p>
          The <code class="literal">swiotlb=force</code> kernel parameter is required for
          DMA access to work for PCI devices on a PV guest. For more
          information about IOMMU and the <code class="literal">swiotlb</code> option see
          the file <code class="filename">boot-options.txt</code> from the package
          <code class="systemitem">kernel-source</code>.
        </p></div></div><div class="sect2 " id="sec-xen-vm-info"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">More information</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vm-info">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vm-info</li></ul></div></div></div></div><p>
        There are several resources on the Internet that provide interesting
        information about PCI Pass-Through:
      </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            <a class="link" href="https://wiki.xenproject.org/wiki/VTd_HowTo" target="_blank">https://wiki.xenproject.org/wiki/VTd_HowTo</a>
          </p></li><li class="listitem "><p>
            <a class="link" href="https://software.intel.com/en-us/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficient-virtualization-of-io-devices/" target="_blank">https://software.intel.com/en-us/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficient-virtualization-of-io-devices/</a>
          </p></li><li class="listitem "><p>
            <a class="link" href="https://support.amd.com/TechDocs/48882_IOMMU.pdf" target="_blank">https://support.amd.com/TechDocs/48882_IOMMU.pdf</a>
          </p></li></ul></div></div></div><div class="sect1 " id="sec-xen-vhost-usbpass"><div class="titlepage"><div><div><h2 class="title"><span class="number">23.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">USB pass-through</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#sec-xen-vhost-usbpass">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>sec-xen-vhost-usbpass</li></ul></div></div></div></div><p>
      There are two methods for passing through individual host USB devices to
      a guest. The first is via an emulated USB device controller, the second
      is using PVUSB.
    </p><div class="sect2 " id="xen-usb-identify"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identify the USB device</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#xen-usb-identify">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>xen-usb-identify</li></ul></div></div></div></div><p>
        Before you can pass through a USB device to the VM Guest, you need to
        identify it on the VM Host Server. Use the <code class="command">lsusb</code> command
        to list the USB devices on the host system:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>lsusb
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
Bus 002 Device 003: ID 0461:4d15 Primax Electronics, Ltd Dell Optical Mouse
Bus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub</pre></div><p>
        To pass through the Dell mouse, for example, specify either the device
        tag in the form <code class="literal">vendor_id:device_id</code> (0461:4d15) or
        the bus address in the form <code class="literal">bus.device</code> (2.3).
        Remember to remove leading zeros, otherwise <code class="command">xl</code> would
        interpret the numbers as octal values.
      </p></div><div class="sect2 " id="xen-usb-emulated"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Emulated USB device</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#xen-usb-emulated">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>xen-usb-emulated</li></ul></div></div></div></div><p>
        In emulated USB, the device model (QEMU) presents an emulated USB
        controller to the guest. The USB device is then controlled from Dom0
        while USB commands are translated between the VM Guest and the host
        USB device. This method is only available to fully virtualized domains
        (HVM).
      </p><p>
        Enable the emulated USB hub with the <code class="option">usb=1</code> option.
        Then specify devices among the list of devices in the configuration
        file along with other emulated devices by using
        <code class="literal">host:USBID</code>. For example:
      </p><div class="verbatim-wrap"><pre class="screen">usb=1
usbdevice=['tablet','host:2.3','host:0424:460']</pre></div></div><div class="sect2 " id="xen-usb-pv"><div class="titlepage"><div><div><h3 class="title"><span class="number">23.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Paravirtualized PVUSB</span> <a title="Permalink" class="permalink" href="cha-xen-vhost.html#xen-usb-pv">#</a><a class="report-bug" rel="nofollow" target="_blank" href="https://github.com/SUSE/doc-sle/edit/main/xml/xen_virtualization_vhost.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>xen_virtualization_vhost.xml</li><li><span class="ds-label">ID: </span>xen-usb-pv</li></ul></div></div></div></div><p>
        PVUSB is a new high performance method for USB Pass-Through from dom0
        to the virtualized guests. With PVUSB, there are two ways to add USB
        devices to a guest:
      </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            via the configuration file at domain creation time
          </p></li><li class="listitem "><p>
            via hotplug while the VM is running
          </p></li></ul></div><p>
        PVUSB uses paravirtualized front- and back-end interfaces. PVUSB
        supports USB 1.1 and USB 2.0, and it works for both PV and HVM guests.
        To use PVUSB, you need usbfront in your guest OS, and usbback in dom0
        or usb back-end in qemu. On <span class="productname"><span class="phrase">openSUSE Leap</span></span>, the USB back-end comes with
        qemu.
        
      </p><p>
        As of Xen 4.7, <code class="command">xl</code> PVUSB support and hotplug support
        is introduced.
      </p><p>
        In the configuration file, specify USB controllers and USB host devices
        with <code class="literal">usbctrl</code> and <code class="literal">usbdev</code>. For
        example, in case of HVM guests:
      </p><div class="verbatim-wrap"><pre class="screen">usbctrl=['type=qusb,version=2,ports=4', 'type=qusb,version=1,ports=4', ]
usbdev=['hostbus=2, hostaddr=1, controller=0,port=1', ]</pre></div><div id="id-1.8.6.2.14.5.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>
          It is important to specify <code class="literal">type=qusb</code> for the
          controller of HVM guests.
        </p></div><p>
        To manage hotplugging PVUSB devices, use the
        <code class="literal">usbctrl-attach</code>, <code class="literal">usbctrl-detach</code>,
        <code class="literal">usb-list</code>, <code class="literal">usbdev-attach</code> and
        <code class="literal">usb-detach</code> subcommands. For example:
      </p><p>
        Create a USB controller which is version USB 1.1 and has 8 ports:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>xl usbctrl-attach test_vm version=1 ports=8 type=qusb</pre></div><p>
        Find the first available controller:port in the domain, and attach USB
        device whose busnum:devnum is 2:3 to it; you can also specify
        <code class="literal">controller</code> and <code class="literal">port</code>:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>xl usbdev-attach test_vm hostbus=2 hostaddr=3</pre></div><p>
        Show all USB controllers and USB devices in the domain:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>xl usb-list test_vm
Devid  Type   BE  state usb-ver ports
0      qusb   0   1     1       8
  Port 1: Bus 002 Device 003
  Port 2:
  Port 3:
  Port 4:
  Port 5:
  Port 6:
  Port 7:
  Port 8:</pre></div><p>
        Detach the USB device under controller 0 port 1:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>xl usbdev-detach test_vm 0 1</pre></div><p>
        Remove the USB controller with the indicated <code class="literal">dev_id</code>,
        and all USB devices under it:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root"># </code>xl usbctrl-detach test_vm dev_id</pre></div><p>
        For more information, see
        <a class="link" href="https://wiki.xenproject.org/wiki/Xen_USB_Passthrough" target="_blank">https://wiki.xenproject.org/wiki/Xen_USB_Passthrough</a>.
      </p></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="cha-xen-network.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 24 </span>Virtual networking</span></a><a class="nav-link" href="part-virt-xen.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Part IV </span>Managing virtual machines with Xen</span></a></div><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2024 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>